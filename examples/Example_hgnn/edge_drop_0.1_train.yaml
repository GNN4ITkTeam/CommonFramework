# CommonFramework configuration
stage: track_building
model: HierarchicalGNN
input_dir: /global/cfs/cdirs/m2616/pmtuan/inferred_data/igcn_14999421_epoch66_redo/ # Should contain the files used in training and inference
stage_dir: /global/cfs/cdirs/m3443/usr/ryanliu/HGNN/edgedrop01/ # A directory to be created that will store logs, artifacts, and output data
project: HGNN_edgedrop # Used in logging
gpus: 4
nodes: 1

# Dataset parameters
data_split: [4000, 100, 1000] # Number of [training, validation, testing] examples[7800, 1000, 1000]
data_config:
    edge_cut: 0.001
    loose_cut: 0.01
    tight_cut: null
    min_hits: 9
    random_drop: 0.1
    signal_weight: 2
    signal_selection: 
        pt: [range, [1000, null]]
        nhits: [range, [3, null]]
    target_selection:
        pt: [range, [500, null]]
        nhits: [range, [3, null]]

node_features: [r, phi, z]
node_scales:   [1000, 3.14, 1000]
num_workers: [16, 16, 16]

# Loss Function
pretraining_steps: 1000
auxiliary_decay: 4000
auxiliary_min: 0.1
emb_ratio: 10
margin: 1

# Model Parameter
model_config:
    d_model: 128
    d_hidden: 128
    n_output_layers: 3
    n_interaction_iterations: 6
    n_hierarchical_iterations: 8
    hidden_activation: GELU
    output_activation: null
    dropout: 0.
    emb_size: 8
    bsparsity: 8
    ssparsity: 5
    resolution: -1.
    cut_momentum: 0.99
    min_size: 3

# Online Evaluation Parameter
metric_to_monitor: tracking_efficiency
metric_mode: max
score_cut: 0.5
matching_fraction: 0.5
matching_style: ATLAS
min_track_length: 5
selection:
    pt: [range, [1000, null]]
    eta: [range, [-4, 4]]
    primary: [isin, [1]]
    nhits: [range, [7, null]]
    pdgId: [notin, [11, -11]]
    
# Training config
warmup: null
lr: 0.008
patience: 5
factor: 0.7
max_epochs: 100
checkpoint: False
# scheduler: CosineAnnealingWarmRestarts
# T_mult: 1