# CommonFramework configuration
stage: graph_construction
model: MetricLearning
input_dir: /mnt/data0/dittmeier/data/gnn4itk/feature_store/ # Should contain the files used in training and inference
stage_dir: /mnt/data0/dittmeier/data/gnn4itk/QAT_MetricLearning_ITK/ # A directory to be created that will store logs, artifacts, and output data
project: CF_QAT_MetricLearning_ITK # Used in logging
gpus: 1
nodes: 1
num_workers: [0, 0]

# Dataset parameters
data_split: [80, 10, 10] # Number of [training, validation, testing] examples

# Truth and weighting parameters. The syntax is as follows:
  # Single value: track[key] == value
  # List of 2 floats: value1 <= track[key] <= value2
  # List with a string as the first value: First value defines the boolean test, the second value is a list or value. Boolean tests are: (in, not_in, is, is_not, within, not_within)
  # All other tracks follow the default: If a true edge, weight=0. If a fake edge, weight=1.

  # NOTE: let parameter sweep find good configuration? evaluated signal purity at 98% signal efficiency?
weighting:
  - weight: 1.
    conditions:
      y: False
  - weight: 0.
    conditions:
      y: True
  - weight: 3.
    conditions:
      y: True
      pt: [500, .inf]
      nhits: [3, .inf]
      primary: True
      pdgId: [not_in, [11, -11]]

# A list of hard cut conditions. Any hits not passing these conditions will be removed from the training and validation dataset.
# By definition, noise will not pass any of these cuts, so any hard cuts will remove noise.
hard_cuts:
  pt: [1000, .inf]

# Model parameters
undirected: True
node_features: [r, phi, z]
node_scales: [1000, 3.14, 1000]
emb_hidden: 512
nb_layer: 4
emb_dim: 12
activation: ReLU
randomisation: 1
points_per_batch: 50000
r_train: 0.1
knn: 50
knn_val: 500
knn_test: 100
norm: True

# Training parameters
warmup: 5
margin: 0.1
lr: 0.01
factor: 0.7
patience: 10
max_epochs: 10
metric_to_monitor: f1
metric_mode: max
# below: to measure purity at fixed efficiency!
log_working_metrics: True
target_purity: 0.14 # 0.006  # reference value from unquantized network

onnx_export: True

# QNN Parameters
quantized_network: True
weight_bit_width_input: 8
weight_bit_width_hidden: 8
weight_bit_width_output: 8
bias: False # does not work yet
bias_quant: Int8Bias  # also does not work yet
activation_qnn: False # tlling the network to use quantReLU()
activation_bit_width_input: 8
activation_bit_width_hidden: 8
activation_bit_width_output: 8
output_activation: False
output_activation_quantization: False
batch_norm: True
layer_norm: False

# Input quantization Parameters, only using fixed point representation
input_quantization: True # also enables QuantIdentity
integer_part: 3
fractional_part: 24

# pruning
pruning_allow: True
l1_loss: False
rewind_lr: False # for rewinding learning rate after pruning

l1_factor: 0.000005
pruning_val_loss: 0.000002
pruning_fn: "l1_unstructured"
pruning_amount: 0.5
pruning_freq: 5
