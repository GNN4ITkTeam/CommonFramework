# CommonFramework configuration
stage: graph_construction
model: MetricLearning
input_dir: MY_DATA_DIR/Example_2/feature_store/ # Should contain the files used in training and inference
stage_dir: MY_DATA_DIR/Example_2/metric_learning/ # A directory to be created that will store logs, artifacts, and output data
project: CF_Example_2_MetricLearning # Used in logging
gpus: 1
nodes: 1
num_workers: [0,0]

# Dataset parameters
data_split: [80, 10, 10] # Number of [training, validation, testing] examples

# Truth and weighting parameters. The syntax is as follows:
  # Single value: track[key] == value
  # List of 2 floats: value1 <= track[key] <= value2
  # List with a string as the first value: First value defines the boolean test, the second value is a list or value. Boolean tests are: (in, not_in, is, is_not, within, not_within)
  # All other tracks follow the default: If a true edge, weight=0. If a fake edge, weight=1.
weighting:
  - weight: 1.
    conditions: 
      y: False
  - weight: 0.
    conditions:
      y: True
  - weight: 3.
    conditions:
      y: True
      pt: [1000, .inf]
      nhits: [3, .inf]
      primary: True
      pdgId: [not_in, [11, -11]]

# A list of hard cut conditions. Any hits not passing these conditions will be removed from the training and validation dataset.
# By definition, noise will not pass any of these cuts, so any hard cuts will remove noise.
# hard_cuts:
#   pt: [1000, .inf]

# Model parameters
undirected: True
node_features: [r,    phi,  z]
node_scales:   [1000, 3.14, 1000]
emb_hidden: 1024
nb_layer: 4
emb_dim: 12
activation: ReLU
randomisation: 1
points_per_batch: 50000
r_train: 0.1
knn: 50
knn_val: 500
knn_test: 100

# Training parameters
warmup: 5
margin: 0.1
lr: 0.01
factor: 0.7
patience: 10
max_epochs: 250
metric_to_monitor: f1
metric_mode: max




##QNN Parameters
quantized_network: True
quantized_dataset: False
activation_qnn: False ## telling the network to use quantReLU()
output_activation: False
output_activation_quantization: False
input_quantization: True # also enables QuantIdentity


weight_bit_width_input: 6
weight_bit_width_hidden: 4
weight_bit_width_output: 6

activation_bit_width_input: 8
activation_bit_width_hidden: 8
activation_bit_width_output: 8
# Input quantization Parameters, only using fixed point representation
integer_part: 5
fractional_part: 10



##pruning 
pruning_allow: False
l1_loss: False
rewind_lr: True # for rewinding learning rate after pruning

prune_list: []
l1_factor: 0.000005
pruning_amount: 0.1
pruning_freq: 150
pruning_val_loss: 0.000002
pruning_fn: "l1_unstructured"
